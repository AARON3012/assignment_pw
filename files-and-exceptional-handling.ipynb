{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''1.Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\nmultiprocessing is a better choice.\n'''\n'''Multithreading and multiprocessing are two common approaches for achieving concurrent execution in programming, but they are suitable for different types of tasks and scenarios. Here’s a discussion of when each is preferable:\n\nScenarios Where Multithreading is Preferable:\n\nI/O-Bound Tasks:\nDescription: Tasks that spend much of their time waiting for input/output operations (like reading from or writing to files, network communication, or database queries).\nExample: A web server handling multiple requests concurrently. While one thread waits for a response from a database, another can serve a different request, maximizing resource utilization.\n\nLow Memory Overhead:\nDescription: Threads share the same memory space, making them lightweight compared to processes.\nExample: In applications where memory usage is critical, like mobile applications, using threads allows for lower overhead than spawning multiple processes.\n\nResponsive User Interfaces:\nDescription: In GUI applications, keeping the user interface responsive while performing background tasks (like loading data) can be achieved through multithreading.\nExample: An application that loads data in the background while allowing the user to interact with the UI remains responsive and provides a better user experience.\n\nShared Data:\nDescription: When threads need to work on shared data or require frequent communication.\nExample: A game engine where multiple threads update the state of the game world and share resources, allowing them to communicate efficiently through shared memory.\n\n\nScenarios Where Multiprocessing is a Better Choice:\n\nCPU-Bound Tasks:\nDescription: Tasks that require significant CPU time and benefit from parallel execution on multiple cores.\nExample: Computational tasks like data processing, mathematical computations, or scientific simulations can leverage multiple CPU cores by using separate processes.\n\nIsolation:\nDescription: Processes have their own memory space, making them safer for certain applications, especially when executing untrusted code.\nExample: Running separate instances of a web server or executing tasks from different clients where isolation is critical for security or stability.\n\nAvoiding Global Interpreter Lock (GIL):\nDescription: In languages like Python, the GIL prevents multiple threads from executing Python bytecode simultaneously. Using multiprocessing bypasses this limitation.\nExample: When performance is critical and tasks can be parallelized, using multiple processes can yield better performance than threads in Python.\n\nCrash Recovery:\nDescription: If a process crashes, it does not affect other processes. This is important for robust applications that need to recover from errors.\nExample: A data processing pipeline where each stage runs in a separate process. If one stage fails, the others can continue running without affecting the entire system.'''\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''2.Describe what a process pool is and how it helps in managing multiple processes efficiently'''\n\n'''A process pool is a design pattern used in concurrent programming to manage a set of worker processes that can execute tasks in parallel. Instead of creating and destroying processes on the fly, a process pool maintains a fixed number of worker processes and reuses them for multiple tasks. This approach can significantly improve performance and resource management in applications that require parallel processing.\n\nKey Features of a Process Pool\n\nFixed Number of Processes:\nA process pool is initialized with a set number of processes. This fixed size helps control the amount of system resources used, preventing the system from being overwhelmed by too many concurrent processes.\n\nTask Queue:\nWhen a task is submitted to the pool, it is added to a queue. Available worker processes pick up tasks from this queue for execution. This helps manage tasks efficiently without the overhead of creating new processes for every single task.\n\nReusability:\nOnce a worker process finishes executing a task, it is returned to the pool and can be reused for another task. This reusability reduces the overhead of process creation and termination.\n\nLoad Balancing:\nThe process pool can manage the distribution of tasks among worker processes, balancing the workload and improving efficiency.\n\nConcurrency Control:\nBy limiting the number of concurrent processes, the process pool can help prevent system resource exhaustion and manage contention for shared resources.\nBenefits of Using a Process Pool\n\nImproved Performance:\nCreating and destroying processes can be expensive in terms of time and resources. A process pool reduces this overhead by maintaining a set of ready-to-use processes.Resource Management:\nA fixed number of processes helps to limit resource usage (like memory and CPU), ensuring that the system remains stable even under heavy loads.\n\nSimplified Code:\nDevelopers can use a process pool without needing to handle the complexities of process management directly. Libraries that implement process pools often provide simple APIs for submitting tasks and retrieving results.\n\nEnhanced Scalability:\nAs workloads increase, a process pool can be easily scaled by adjusting the number of worker processes, making it suitable for applications that experience varying loads.\n\nError Handling:\nMany process pool implementations provide mechanisms for handling errors in worker processes, allowing for easier debugging and recovery from failures.\nExample in Python\nIn Python, the concurrent.futures module provides a simple way to work with process pools using the ProcessPoolExecutor. Here’s a brief example:\n\nCODE:\nfrom concurrent.futures import ProcessPoolExecutor\nimport os\nimport time\n\ndef worker_function(x):\n    time.sleep(1)  # Simulate a time-consuming task\n    return f'Process {os.getpid()} finished processing {x}'\n\n# Create a process pool with 4 worker processes\nwith ProcessPoolExecutor(max_workers=4) as executor:\n    results = list(executor.map(worker_function, range(10)))\n\n# Print results\nfor result in results:\n    print(result)\nIn this Example:\nWorker Function: A simple function that simulates a time-consuming task by sleeping for one second.\nProcess Pool: Created using ProcessPoolExecutor with a maximum of 4 worker processes.\nTask Submission: The map function submits tasks to the pool and collects the results.\nOutput: Each worker process completes tasks concurrently, demonstrating efficient management of multiple processes.'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''3.Explain what multiprocessing is and why it is used in Python programs.\n'''\n'''Multiprocessing is a programming paradigm that allows a program to execute multiple processes simultaneously, taking advantage of multiple CPU cores to improve performance and responsiveness. In Python, the multiprocessing module provides a straightforward way to create and manage separate processes, allowing you to run tasks in parallel rather than sequentially.\n\nKey Features of Multiprocessing\n\nMultiple Processes:\nUnlike multithreading, which uses threads within a single process, multiprocessing creates completely separate processes. Each process has its own memory space, which provides isolation from other processes.\n\nTrue Parallelism:\nMultiprocessing enables true parallel execution of tasks. This is particularly important in CPU-bound applications, as it allows multiple processes to run on different CPU cores simultaneously.\n\nProcess-Based Concurrency:\nProcesses do not share the same memory space, which eliminates issues related to race conditions and data corruption that can occur in multithreaded applications due to shared memory.\n\nCommunication Between Processes:\nThe multiprocessing module provides mechanisms like pipes and queues for inter-process communication (IPC), allowing processes to exchange data safely.\n\nSupport for Different Platforms:\nThe multiprocessing module is cross-platform, meaning it works on both Unix-like and Windows operating systems.\nWhy Use Multiprocessing in Python?\n\nBypassing the Global Interpreter Lock (GIL):\nPython's GIL allows only one thread to execute Python bytecode at a time, which can be a bottleneck in CPU-bound programs. Multiprocessing bypasses this limitation by using separate processes, each with its own Python interpreter and memory space.\n\nImproved Performance for CPU-Bound Tasks:\nFor tasks that require heavy computations (e.g., numerical simulations, data processing, machine learning), multiprocessing can significantly improve performance by utilizing multiple cores effectively.\n\nIncreased Responsiveness:\nIn applications that require long-running tasks, using multiprocessing can keep the main program responsive by delegating heavy computations to worker processes.\n\nIsolation and Stability:\nSince processes run in their own memory space, a crash in one process does not affect others. This isolation can be beneficial for error handling and recovery in complex applications.\n\nEasier Data Sharing:\nThe multiprocessing module provides features for sharing data between processes, such as Value and Array, making it easier to work with shared data in a parallel computing environment.\nExample of Multiprocessing in Python\nHere’s a simple example demonstrating how to use the multiprocessing module to run tasks in parallel:\n\ncode\nimport multiprocessing\nimport time\n\ndef worker_function(n):\n    time.sleep(1)  # Simulate a time-consuming task\n    return f'Worker {n} finished'\n\nif __name__ == '__main__':\n    # Create a pool of worker processes\n    with multiprocessing.Pool(processes=4) as pool:\n        results = pool.map(worker_function, range(5))\n    \n    # Print results\n    for result in results:\n        print(result)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''4.Write a Python program using multithreading where one thread adds numbers to a list, and another\nthread removes numbers from the list. Implement a mechanism to avoid race conditions using\nthreading.Lock.'''\nimport threading\nimport time\nimport random\n\n# Shared list\nshared_list = []\n# Create a lock\nlock = threading.Lock()\n\ndef add_numbers():\n    \"\"\"Function to add numbers to the shared list.\"\"\"\n    for i in range(10):\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate time taken to add\n        with lock:  # Acquire lock before modifying the list\n            shared_list.append(i)\n            print(f\"Added {i} to the list. Current list: {shared_list}\")\n\ndef remove_numbers():\n    \"\"\"Function to remove numbers from the shared list.\"\"\"\n    for i in range(10):\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate time taken to remove\n        with lock:  # Acquire lock before modifying the list\n            if shared_list:  # Check if the list is not empty\n                removed = shared_list.pop(0)\n                print(f\"Removed {removed} from the list. Current list: {shared_list}\")\n            else:\n                print(\"List is empty. Cannot remove any number.\")\n\n# Create threads\nadd_thread = threading.Thread(target=add_numbers)\nremove_thread = threading.Thread(target=remove_numbers)\n\n# Start threads\nadd_thread.start()\nremove_thread.start()\n\n# Wait for both threads to complete\nadd_thread.join()\nremove_thread.join()\n\nprint(\"Final list:\", shared_list)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T16:36:29.481274Z","iopub.execute_input":"2024-10-19T16:36:29.481587Z","iopub.status.idle":"2024-10-19T16:36:32.928270Z","shell.execute_reply.started":"2024-10-19T16:36:29.481552Z","shell.execute_reply":"2024-10-19T16:36:32.927266Z"}},"outputs":[{"name":"stdout","text":"Added 0 to the list. Current list: [0]\nRemoved 0 from the list. Current list: []\nList is empty. Cannot remove any number.\nAdded 1 to the list. Current list: [1]\nAdded 2 to the list. Current list: [1, 2]\nRemoved 1 from the list. Current list: [2]\nAdded 3 to the list. Current list: [2, 3]\nRemoved 2 from the list. Current list: [3]\nAdded 4 to the list. Current list: [3, 4]\nRemoved 3 from the list. Current list: [4]\nAdded 5 to the list. Current list: [4, 5]\nRemoved 4 from the list. Current list: [5]\nRemoved 5 from the list. Current list: []\nAdded 6 to the list. Current list: [6]\nAdded 7 to the list. Current list: [6, 7]\nRemoved 6 from the list. Current list: [7]\nAdded 8 to the list. Current list: [7, 8]\nRemoved 7 from the list. Current list: [8]\nAdded 9 to the list. Current list: [8, 9]\nRemoved 8 from the list. Current list: [9]\nFinal list: [9]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"'''5. Describe the methods and tools available in Python for safely sharing data between threads and\nprocesses.'''\n\n'''In Python, safely sharing data between threads and processes is essential for ensuring data integrity and preventing race conditions. Here are the primary methods and tools available for managing shared data in both multithreading and multiprocessing contexts:\n\nSharing Data Between Threads\n\nthreading.Lock:\nDescription: A lock is a synchronization primitive that allows only one thread to access a shared resource at a time.\nUsage: The with statement is typically used to acquire and release the lock, ensuring that the lock is released even if an exception occurs.\n\nExample:\nCode\nimport threading\n\nlock = threading.Lock()\nshared_data = []\n\ndef thread_function():\n    with lock:\n        # Access shared_data safely\n        shared_data.append(1)\n\nthreading.RLock:\nDescription: A reentrant lock allows a thread to acquire the same lock multiple times without causing a deadlock.\nUsage: Useful in scenarios where a thread may need to enter a critical section multiple times.\nExample:\nCode\nimport threading\n\nrlock = threading.RLock()\nshared_data = []\n\ndef thread_function():\n    with rlock:\n        with rlock:  # Can acquire it again\n            shared_data.append(1)\n\nthreading.Condition:\nDescription: A condition variable allows threads to wait until a certain condition is met, enabling more complex thread synchronization.\nUsage: Useful for implementing producer-consumer scenarios.\nExample:\nCode\nimport threading\n\ncondition = threading.Condition()\nshared_data = []\n\ndef producer():\n    with condition:\n        shared_data.append(1)\n        condition.notify()  # Notify waiting threads\n\ndef consumer():\n    with condition:\n        condition.wait()  # Wait until notified\n        print(shared_data)\n\nthreading.Event:\nDescription: An event is a simple synchronization primitive that can be set (to indicate that an event has occurred) or cleared.\nUsage: Useful for signaling between threads.\nExample:\n\ncode\nimport threading\n\nevent = threading.Event()\n\ndef wait_for_event():\n    print(\"Waiting for event...\")\n    event.wait()  # Block until the event is set\n    print(\"Event occurred!\")\n\ndef trigger_event():\n    event.set()  # Set the event, unblocking waiting threads\n\nQueue:\nDescription: A thread-safe queue provided by the queue module, which can be used to pass data between threads safely.\nUsage: Suitable for implementing producer-consumer patterns.\nExample:\ncode\nimport threading\nimport queue\n\nq = queue.Queue()\n\ndef producer():\n    q.put(1)  # Add item to queue\n\ndef consumer():\n    item = q.get()  # Remove item from queue\nSharing Data Between Processes\n\nmultiprocessing.Queue:\nDescription: A queue that allows processes to communicate with each other by sending and receiving data.\nUsage: Ideal for implementing producer-consumer models between processes.\nExample:\ncode\nfrom multiprocessing import Process, Queue\n\ndef producer(q):\n    q.put(1)\n\ndef consumer(q):\n    item = q.get()\n\nif __name__ == '__main__':\n    q = Queue()\n    p1 = Process(target=producer, args=(q,))\n    p2 = Process(target=consumer, args=(q,))\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n\nmultiprocessing.Lock:\nDescription: A lock that works similarly to threading.Lock, used for synchronizing access to shared resources across multiple processes.\nUsage: Ensures that only one process can modify a shared resource at a time.\nExample:\ncode\nfrom multiprocessing import Process, Lock\n\ndef worker(lock):\n    with lock:\n        # Access shared resource safely\n        pass\n\nif __name__ == '__main__':\n    lock = Lock()\n    p = Process(target=worker, args=(lock,))\n    p.start()\n    p.join()\n\nmultiprocessing.Value and multiprocessing.Array:\nDescription: Shared data types that allow for sharing simple data types and arrays between processes.\nUsage: Useful for sharing state without needing complex IPC mechanisms.\nExample:\ncode\nfrom multiprocessing import Process, Value, Array\n\ndef worker(shared_value, shared_array):\n    shared_value.value += 1\n    for i in range(len(shared_array)):\n        shared_array[i] += 1\n\nif __name__ == '__main__':\n    value = Value('i', 0)  # Shared integer\n    array = Array('i', [0, 0, 0])  # Shared array\n    p = Process(target=worker, args=(value, array))\n    p.start()\n    p.join()\n\nmultiprocessing.Manager:\nDescription: Provides a way to create shared data structures (like lists, dictionaries) that can be accessed by multiple processes.\nUsage: Useful for complex data sharing requirements.\nExample:\ncode\nfrom multiprocessing import Process, Manager\n\ndef worker(shared_dict):\n    shared_dict['key'] = 'value'\n\nif __name__ == '__main__':\n    manager = Manager()\n    shared_dict = manager.dict()\n    p = Process(target=worker, args=(shared_dict,))\n    p.start()\n    p.join()\n    print(shared_dict)'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\ndoing so.'''\n\n'''Handling exceptions in concurrent programs is crucial for several reasons, including ensuring program stability, maintaining data integrity, and providing clear feedback on errors. In concurrent environments, multiple threads or processes run simultaneously, which can complicate error handling significantly. Here are the key reasons why exception handling is essential in concurrent programs, along with techniques for effectively managing exceptions:\n\nImportance of Exception Handling in Concurrent Programs\n\nPreventing Program Crashes:\nUnhandled exceptions can lead to program termination, resulting in loss of unsaved data, user frustration, and degraded user experience. Proper exception handling can ensure that the program remains stable even when errors occur.\n\nMaintaining Data Integrity:\nConcurrent programs often manipulate shared resources. If an exception occurs while accessing or modifying shared data, it could leave the data in an inconsistent state. Proper exception handling can help rollback changes or restore data integrity.\n\nDebugging and Logging:\nException handling allows developers to capture and log error information. This information is invaluable for diagnosing issues in complex concurrent systems, where identifying the source of a problem can be challenging.\n\nGraceful Degradation:\nIn many applications, especially in user-facing ones, it is important to provide a fallback mechanism or degrade functionality gracefully rather than failing outright. Exception handling allows developers to implement such strategies.\n\nInter-Thread/Process Communication:\nIn concurrent programs, one thread or process may need to inform others about errors that occur. Proper exception handling ensures that errors can be propagated appropriately across threads or processes.\nTechniques for Handling Exceptions in Concurrent Programs\n\nTry-Except Blocks:\nSurrounding critical sections of code with try-except blocks allows you to catch and handle exceptions at the point where they occur. This is fundamental in both threads and processes.\nExample:\ncode\nimport threading\n\ndef worker():\n    try:\n        # Code that might raise an exception\n        raise ValueError(\"An error occurred in the worker thread\")\n    except ValueError as e:\n        print(f\"Handled exception: {e}\")\n\nthread = threading.Thread(target=worker)\nthread.start()\nthread.join()\n\nLogging:\nUse logging frameworks to record exceptions when they occur. This can help in understanding the application’s behavior over time and diagnosing issues.\nExample:\ncode\nimport logging\nimport threading\n\nlogging.basicConfig(level=logging.ERROR)\n\ndef worker():\n    try:\n        raise ValueError(\"An error occurred\")\n    except Exception as e:\n        logging.error(\"Exception in worker thread\", exc_info=True)\n\nthread = threading.Thread(target=worker)\nthread.start()\nthread.join()\n\nCustom Exception Classes:\nCreate custom exception classes to handle specific error types in concurrent environments. This can make it easier to catch and respond to different error conditions appropriately.\nExample:\ncode\nclass MyCustomError(Exception):\n    pass\n\ndef worker():\n    raise MyCustomError(\"Custom error in worker\")\n\ntry:\n    worker()\nexcept MyCustomError as e:\n    print(f\"Caught custom exception: {e}\")\n\nThread and Process Pools:\nWhen using thread or process pools, such as those provided by the concurrent.futures module, exceptions raised in worker threads or processes can be captured in the main thread by checking the results.\nExample:\ncode\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef worker():\n    raise ValueError(\"Error in thread\")\n\nwith ThreadPoolExecutor() as executor:\n    future = executor.submit(worker)\n    try:\n        future.result()  # This will raise the exception from the worker\n    except Exception as e:\n        print(f\"Caught exception from thread: {e}\")\n\nSignal Handling:\nFor processes, you can set up signal handlers to catch specific termination signals and handle cleanup or logging accordingly. This is especially relevant for long-running applications.\nExample:\ncode\nimport signal\nimport time\n\ndef signal_handler(sig, frame):\n    print(\"Signal caught! Cleaning up...\")\n    exit(0)\n\nsignal.signal(signal.SIGINT, signal_handler)\n\nwhile True:\n    time.sleep(1)\n\nUsing Futures:\nWhen dealing with asynchronous operations, using concurrent.futures allows you to manage exceptions in a structured way. You can retrieve exceptions raised in futures without blocking the main thread.\nExample:\ncode\nfrom concurrent.futures import Future, ThreadPoolExecutor\n\ndef task():\n    raise RuntimeError(\"Error in task\")\n\nwith ThreadPoolExecutor() as executor:\n    future = executor.submit(task)\n    try:\n        future.result()  # Raises the RuntimeError here\n    except RuntimeError as e:\n        print(f\"Caught exception: {e}\")'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\nUse concurrent.futures.ThreadPoolExecutor to manage the threads.'''\nimport concurrent.futures\nimport math\n\ndef calculate_factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    return math.factorial(n)\n\ndef main():\n    # Define the numbers for which we want to calculate the factorial\n    numbers = range(1, 11)\n\n    # Use ThreadPoolExecutor to calculate factorials concurrently\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # Map the function to the numbers, this will return results in the same order\n        results = list(executor.map(calculate_factorial, numbers))\n\n    # Print the results\n    for number, factorial in zip(numbers, results):\n        print(f\"The factorial of {number} is {factorial}\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T16:44:59.199049Z","iopub.execute_input":"2024-10-19T16:44:59.199793Z","iopub.status.idle":"2024-10-19T16:44:59.208588Z","shell.execute_reply.started":"2024-10-19T16:44:59.199742Z","shell.execute_reply":"2024-10-19T16:44:59.207566Z"}},"outputs":[{"name":"stdout","text":"The factorial of 1 is 1\nThe factorial of 2 is 2\nThe factorial of 3 is 6\nThe factorial of 4 is 24\nThe factorial of 5 is 120\nThe factorial of 6 is 720\nThe factorial of 7 is 5040\nThe factorial of 8 is 40320\nThe factorial of 9 is 362880\nThe factorial of 10 is 3628800\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"'''8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\nparallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\nprocesses).'''\nimport multiprocessing\nimport time\n\ndef compute_square(n):\n    \"\"\"Compute the square of a number.\"\"\"\n    return n * n\n\ndef main():\n    numbers = range(1, 11)  # Numbers from 1 to 10\n\n    # Define pool sizes to test\n    pool_sizes = [2, 4, 8]\n\n    for size in pool_sizes:\n        print(f\"\\nUsing pool size: {size}\")\n        start_time = time.time()\n\n        # Create a multiprocessing pool with the specified size\n        with multiprocessing.Pool(processes=size) as pool:\n            # Map the compute_square function to the numbers\n            results = pool.map(compute_square, numbers)\n\n        end_time = time.time()\n        duration = end_time - start_time\n\n        # Print the results\n        print(f\"Squares: {results}\")\n        print(f\"Time taken: {duration:.4f} seconds\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-19T16:45:47.978720Z","iopub.execute_input":"2024-10-19T16:45:47.979615Z","iopub.status.idle":"2024-10-19T16:45:48.098451Z","shell.execute_reply.started":"2024-10-19T16:45:47.979572Z","shell.execute_reply":"2024-10-19T16:45:48.097313Z"}},"outputs":[{"name":"stdout","text":"\nUsing pool size: 2\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nTime taken: 0.0302 seconds\n\nUsing pool size: 4\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nTime taken: 0.0269 seconds\n\nUsing pool size: 8\nSquares: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nTime taken: 0.0494 seconds\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}